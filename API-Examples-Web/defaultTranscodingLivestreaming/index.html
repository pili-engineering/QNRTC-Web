<!DOCTYPE html>
<html lang="en">

    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <title>Default Transcoding Livestreaming</title>
        <link href="../assets/bootstrap.min.css" rel="stylesheet">
        <link href="../assets/index.css" rel="stylesheet">
    </head>

    <body>

        <nav class="container-fluid demo-nav">
            <div>Qiniu RTC Web SDK API Demos</div>
            <a class="navbar-brand" href="https://github.com/pili-engineering/QNRTC-Web">
                <svg height="32" viewBox="0 0 16 16" version="1.1" width="32" aria-hidden="true">
                    <path fill-rule="evenodd"
                        d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z">
                    </path>
                </svg>
            </a>
        </nav>

        <div class="container">
            <form>
                <div class="mb-3">
                    <label class="form-label" for="room-token"> Room Token </label>
                    <input type="text" class="form-control" id="room-token" required>
                    <div class="form-text">
                        Don't know how to create a token? Refer to this <a
                            href="https://developer.qiniu.com/rtc/8813/roomToken">doc</a>
                    </div>
                </div>
                <button class="btn btn-primary" id="start-stream-btn">Start</button>
                <button class="btn btn-primary" disabled id="stop-stream-btn">Stop</button>
            </form>
        </div>


        <div class="container" id="media-container"></div>

        <script src="../assets/bootstrap.bundle.min.js"></script>
        <script src="../assets/qnweb-rtc.js"></script>
        <script src="../assets/index.js"></script>

        <script>
            const client = QNRTC.createClient();

            const startBtn = document.getElementById("start-stream-btn");
            const stopBtn = document.getElementById("stop-stream-btn");

            const roomTokenInput = document.getElementById("room-token");

            let localTracks = [];

            // 合流后画布宽高
            // 这里要和浏览器控制台配置的连麦合流转推配置一致
            const width = 720;
            const height = 1080;

            // 房间内所有的 tracks
            let allVideoTracks = new Set();
            let allAudioTracks = new Set();

            // x, y, width, height
            // 根据 allVideoTracks 自动配置合流布局
            // 按照均等分配的原则分配每个 track 在画布的位置
            // 1 => 占据全部
            // 2 => 左右等分
            // 3 => 四等分
            // 4 => 四等分
            // 5 => 2 row 3 colum
            // ...
            function getVideoConfig() {
                let x = 1;
                let y = 1;
                let flag = true;
                while (x * y < allVideoTracks.size) {
                    if (flag) {
                        x += 1;
                    }
                    if (!flag) {
                        y += 1;
                    }
                    flag = !flag;
                }
                const cellWidth = Math.floor(width / x);
                const cellHeight = Math.floor(height / y);

                let res = [];
                let tracks = [...allVideoTracks];
                for (let i = 0; i < tracks.length; i++) {
                    let config = {};
                    config.x = cellWidth * (i % x);
                    config.y = cellHeight * Math.floor(i / x);
                    config.width = (i + 1) % x === 0 ? width - config.x : cellWidth;
                    config.height = Math.floor(i / x) + 1 === y ? height - config.y : cellHeight;
                    config.trackID = tracks[i];
                    res.push(config);
                }

                return res;
            }

            // 根据当前房间内所有的 track 信息，更新推流布局
            function setTranscodingTracks() {
                let transcodingTracks = [...[...allAudioTracks].map(trackID => ({ trackID })), ...getVideoConfig()];

                // 默认合流，不需要传递 streamID
                client.setTranscodingLiveStreamingTracks(null, transcodingTracks)
                    .then(() => {
                        console.log("set track success", transcodingTracks);
                    })
                    .catch(e => {
                        console.log("set track fail", e, transcodingTracks);
                    });
            }

            function handleUserPublished(userID, tracks) {
                for (const track of tracks) {
                    if (track.isAudio()) {
                        allAudioTracks.add(track.trackID);
                    } else {
                        allVideoTracks.add(track.trackID);
                    }
                }
                setTranscodingTracks();
            }

            function handleUserUnPublished(userID, tracks) {
                for (const track of tracks) {
                    if (track.isAudio()) {
                        allAudioTracks.delete(track.trackID);
                    } else {
                        allVideoTracks.delete(track.trackID);
                    }
                }
                setTranscodingTracks();
            }

            startBtn.onclick = async (e) => {
                e.preventDefault();
                try {
                    client.on("user-published", handleUserPublished);
                    client.on("user-unpublished", handleUserUnPublished);

                    await client.join(roomTokenInput.value);

                    const cameraTrack = await QNRTC.createCameraVideoTrack();
                    const microphoneTrack = await QNRTC.createMicrophoneAudioTrack();
                    localTracks.push(cameraTrack, microphoneTrack);

                    await client.publish(localTracks);
                    allVideoTracks.add(cameraTrack.trackID);
                    allAudioTracks.add(microphoneTrack.trackID);

                    setTranscodingTracks();
                    stopBtn.disabled = false;
                    startBtn.disabled = true;

                } catch (e) {
                    alert(e.message, "warning");
                }
            };

            stopBtn.onclick = (e) => {
                e.preventDefault();
                client.stopTranscodingLiveStreaming()
                    .then(() => {
                        return client.leave();
                    })
                    .then(() => {
                        for (const track of localTracks) {
                            track.destroy();
                        }
                        localTracks = [];
                        allAudioTracks = new Set();
                        allVideoTracks = new Set();
                        startBtn.disabled = false;
                        stopBtn.disabled = true;
                    })
                    .catch((e) => {
                        alert(e.message, "warning");
                    });
            }

        </script>

    </body>

</html>